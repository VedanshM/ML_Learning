{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow 2\n",
    "Tensorflow 2 combines tf and keras, and thus only require us to make outline of NN, and make use of prebuilt functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-12T12:16:25.806128Z",
     "start_time": "2020-07-12T12:16:24.685356Z"
    }
   },
   "outputs": [],
   "source": [
    "## Basic imports\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally the given code acan be used to preprocess data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for image data like MNIST, CIFAR\n",
    "def preprocess_data(augment=True, valSize=7000, shuffleTest=True):\n",
    "    dataset = tf.keras.datasets.cifar10\n",
    "    (x_train, y_train), (x_test, y_test) = dataset.load_data()\n",
    "    x_train /= 255\n",
    "    x_test /= 255\n",
    "    if shuffleTest:\n",
    "        permut = np.random.shuffle(np.arrange(x_test[0]))\n",
    "        x_test = x_test[permut]\n",
    "        y_test = y_test[permut]\n",
    "    x_val, x_test = x_test[:valSize], x_test[valSize:]\n",
    "    y_val, y_test = y_test[:valSize], y_test[valSize:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic step is to create a model. like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(layers = [])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the layers arg is a list which the strucure of NN/model.  It contains layers specifications, dropouts, flattening layers, etc. So the thing is that the model need to know the input_shape of the model (usually (nx, 1) or be it the what data has and flatten it later).\n",
    "after that just give the next layer's no of units and activation function. It's like stack and thus pop() can be used. Layers/etc. can also be added later with add() command. if at alst all the things are specified then U can use  \n",
    "`` model.summary()``   \n",
    "to view summary details of ur model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good way to do that is like : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n  = [n_x,  10, 4 ,C]\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(n[0], ))\n",
    "])\n",
    "\n",
    "for i in self.n[1: -1]:\n",
    "    self.model.add(tf.keras.layers.Dense(i, activation=tf.nn.relu))\n",
    "self.model.add(tf.keras.layers.Dense( self.n[-1], activation=tf.nn.softmax ))\n",
    "self.model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note that is u use Softmax as the activation function in the last layer then in loss (crossentropy family) use from_logits=Flase else the loss function again applies the softmax."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compile\n",
    "+ optimizer : GD, SGD, adam etc. Hyperparameters like learning rate, momentum, epsilon etc. are part of it.\n",
    "+ loss : loss function generally a crossEntropy one. Use sparse entropy if labels contain an integer to denote the class of Input, but use crossEntropy for one_hat versions.\n",
    "+ metrics : usually used as ['accuracy']  \n",
    "\n",
    "##### Fit\n",
    "it accepts the arguments like the x_train and y_train data for training , U specify the miniBatchSize here as `batch_size`. 1 epoch is the number of passes over the entire dataset. The functions returns a history object not usually used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate),\n",
    "                      loss=tf.keras.losses.categorical_crossentropy,\n",
    "                      metrics=['accuracy'])\n",
    "model.fit(self.x_train, self.y_train,\n",
    "                  epochs=epochCnt, batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now to run this model on your test set, use evaluate method. If u want to know the result of a single input example simply use `model(x)` and this will return the output of the trained NN. If u wish to have outputs for multiple inputs use `model.predict(x)` ) this computes predictions batchwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(xTest, yTest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "markdown",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": "markdown",
   "file_extension": ".md",
   "mimetype": "text/markdown",
   "name": "Markdown",
   "pygments_lexer": "markdown",
   "version": "3.8.2-final"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}